ë°•ì‚¬ë‹˜, **'[í´ë¼ìš°ë“œ ì „ìš© ì „ì²´ ì½”ë“œ]'**ë€ ë°•ì‚¬ë‹˜ì˜ PCì—ì„œë§Œ ëŒì•„ê°€ë˜ í”„ë¡œê·¸ë¨ì„ ì¸í„°ë„·(Streamlit Cloud) í™˜ê²½ì—ì„œë„ ë˜‘ë˜‘í•˜ê²Œ ì‘ë™í•˜ë„ë¡ ìˆ˜ì •í•œ ìµœì¢… ì„¤ê³„ë„ë¥¼ ë§í•©ë‹ˆë‹¤.

ê°€ì¥ í° ì°¨ì´ì ì€ ë³´ì•ˆì…ë‹ˆë‹¤. PCì—ì„œëŠ” google_key.json íŒŒì¼ì„ ì§ì ‘ ë¶ˆëŸ¬ì™”ì§€ë§Œ, ì¸í„°ë„·ì— ì´ íŒŒì¼ì„ ê·¸ëŒ€ë¡œ ì˜¬ë¦¬ë©´ í•´í‚¹ì˜ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì´ ì½”ë“œëŠ” **'ë¹„ë°€ ê¸ˆê³ (Secrets)'**ì— ì €ì¥ëœ í‚¤ ì •ë³´ë¥¼ ì•ˆì „í•˜ê²Œ êº¼ë‚´ ì“°ë„ë¡ ì„¤ê³„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ì•„ë˜ ë°•ìŠ¤ ì•ˆì˜ ì½”ë“œê°€ ë°”ë¡œ ê·¸ ì „ì²´ ì½”ë“œì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ í†µì§¸ë¡œ ë³µì‚¬í•´ì„œ ê¹ƒí—ˆë¸Œì˜ app.py ë³¸ë¬¸ì— ë¶™ì—¬ë„£ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤.

ğŸ“„ app.pyì— ë¶™ì—¬ë„£ì„ [í´ë¼ìš°ë“œ ì „ìš© ì „ì²´ ì½”ë“œ]
Python

from google.cloud import texttospeech
import fitz
import re
import os
import json

# --- 1. êµ¬ê¸€ ì¸ì¦ ì„¤ì • (í´ë¼ìš°ë“œ/ë¡œì»¬ ê²¸ìš©) ---
# ìŠ¤íŠ¸ë¦¼ë¦¿ í´ë¼ìš°ë“œì˜ 'Secrets'ì— í‚¤ë¥¼ ë„£ì—ˆì„ ë•Œì™€ ë‚´ PCì—ì„œ ëŒë¦´ ë•Œë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.
if "google_creds" in st.secrets:
    # [í´ë¼ìš°ë“œ í™˜ê²½] Secretsì— ì €ì¥ëœ ì •ë³´ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ë§Œë“¤ì–´ ì¸ì¦
    creds_dict = dict(st.secrets["google_creds"])
    with open("temp_key.json", "w") as f:
        json.dump(creds_dict, f)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "temp_key.json"
else:
    # [ë¡œì»¬ PC í™˜ê²½] ê¸°ì¡´ì²˜ëŸ¼ google_key.json íŒŒì¼ ì‚¬ìš©
    current_dir = os.path.dirname(os.path.abspath(__file__))
    KEY_PATH = os.path.join(current_dir, "google_key.json")
    if os.path.exists(KEY_PATH):
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = KEY_PATH

# --- 2. ìŒì› ì „ìš© í•„í„°ë§ (ì²­ê° ìµœì í™”) ---
def clean_for_audio(text, is_chapter=False):
    # ì˜ì–´ ë³‘ê¸° ë° ì¸ìš©/ê°ì£¼ ìƒëµ
    text = re.sub(r'\([a-zA-Z\s,./-]+\)', '', text)
    text = re.sub(r'\([^)]*\d{4}[^)]*\)', '', text)
    text = re.sub(r'\[\d+[\d\s,]*\]', '', text)
    
    # 'ì„œë¡ ' ë° ì¥ ì œëª© ë’¤ íœ´ì§€ê¸°(1.5ì´ˆ)
    text = text.replace("ì„œë¡ ", "ì„œë¡  <break time='1.5s'/>")
    if is_chapter:
        text = re.sub(r'^([^.!?\n]+)', r'\1 <break time="1.5s"/>', text)
    return text

# --- 3. í”„ë¦¬ë¯¸ì—„ TTS ì—”ì§„ (1.1ë°°ì†) ---
def google_premium_tts(raw_text, filename, is_chapter=False):
    if not raw_text.strip(): return None
    try:
        client = texttospeech.TextToSpeechClient()
        audio_text = clean_for_audio(raw_text, is_chapter)
        
        max_chunk = 1000 
        text_chunks = [audio_text[i:i+max_chunk] for i in range(0, len(audio_text), max_chunk)]
        
        combined_audio = b""
        for chunk in text_chunks:
            ssml_text = f"<speak><prosody rate='1.1' pitch='0.0st'>{chunk}</prosody></speak>"
            response = client.synthesize_speech(
                input=texttospeech.SynthesisInput(ssml=ssml_text),
                voice=texttospeech.VoiceSelectionParams(
                    language_code="ko-KR", name="ko-KR-Neural2-B",
                    ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
                ),
                audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3, speaking_rate=1.1)
            )
            combined_audio += response.audio_content
        return combined_audio
    except Exception as e:
        st.error(f"âš ï¸ TTS ì˜¤ë¥˜: {str(e)}")
        return None

# --- 4. í…ìŠ¤íŠ¸ ì •ì œ ë¡œì§ ---
def narrative_word_healer(text):
    lines = text.split('\n')
    clean_lines = []
    meta_keywords = ['ISSN', 'DOI', 'http', 'Vol', 'No', 'Journal', 'ë°œí–‰', 'pp.', 'â“’', 'Copyright']
    
    for line in lines:
        l = line.strip()
        if l.isdigit() and len(l) < 4: continue 
        if any(k.lower() in l.lower() for k in meta_keywords): continue
        clean_lines.append(l)
    
    text = " ".join(clean_lines)
    text = re.sub(r'([ê°€-í£])\s?\n\s?([ê°€-í£])', r'\1\2', text)
    text = re.sub(r'([ì€ëŠ”ì´ê°€ì„ë¥¼ì˜ì—ë¡œì™€ê³¼,.\)\]!\?])\s?\n', r'\1 ', text)
    return re.sub(r'\s+', ' ', text).strip()

def extract_thesis(doc):
    pages_content = [page.get_text("text") for page in doc]
    
    # ì œëª© ì¶”ì¶œ (ìª½ë²ˆí˜¸ ì œê±° í¬í•¨)
    first_page_lines = pages_content[0].split('\n')
    title_parts = []
    for line in first_page_lines:
        l = line.strip()
        if not l or any(k in l for k in ['ISSN', 'DOI', 'http']): continue
        if '*' in l or 'ìš”ì•½' in l or 'Abstract' in l or 'â… .' in l: break
        title_parts.append(l)
    title = re.sub(r'\s*\d+$', '', " ".join(title_parts)).strip()

    # ë³¸ë¬¸ ë° ìš”ì•½ ì¶”ì¶œ
    full_text = narrative_word_healer("\n".join(pages_content))
    main_body = full_text.split("ì°¸ê³ ë¬¸í—Œ")[0].split("References")[0]
    
    abs_match = re.search(r'(êµ­\s*ë¬¸\s*ìš”\s*ì•½|ìš”\s*ì•½)(.*?)(Abstract|ì£¼\s*ì œ\s*ì–´|â… \.|1\.)', main_body, re.S)
    summary = narrative_word_healer(abs_match.group(2)) if abs_match else "ìš”ì•½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    chapters = []
    ch_splits = re.split(r'(ì œ\s*[1-5]\s*ì¥|â… \.|â…¡\.|â…¢\.|â…£\.|â…¤\.)', main_body)
    for i in range(1, len(ch_splits), 2):
        name = ch_splits[i].strip()
        content = ch_splits[i+1].strip()
        if len(content) > 50:
            chapters.append({"name": name, "content": f"{name}. {content}"})

    return title, summary, chapters

# --- 5. ë©”ì¸ UI ---
st.set_page_config(page_title="ë…¼ë¬¸ ë‚˜ë ˆì´í„° Cloud", layout="wide")
st.title("ğŸ™ï¸ ë…¼ë¬¸ ë‚˜ë ˆì´í„° (Cloud ë²„ì „)")

uploaded_file = st.file_uploader("ë…¼ë¬¸ PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    if 'thesis_data' not in st.session_state:
        with st.spinner("ë…¼ë¬¸ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
            t, s, c = extract_thesis(doc)
            st.session_state.thesis_data = {'title': t, 'summary': s, 'chapters': c}

    data = st.session_state.thesis_data
    f_title = st.text_input("ğŸ“„ ë…¼ë¬¸ ì œëª© (ìˆ˜ì • ê°€ëŠ¥)", data['title'])
    
    if st.button("ğŸ”Š ì£¼ì œ + ìš”ì•½ ìŒì› ìƒì„±"):
        audio = google_premium_tts(f"{f_title}. {data['summary']}", "summary.mp3", is_chapter=True)
        if audio:
            st.audio(audio)
            st.download_button("ğŸ“¥ MP3 ë‹¤ìš´ë¡œë“œ (summary.mp3)", audio, "summary.mp3", "audio/mp3")

    st.divider()
    for idx, ch in enumerate(data['chapters']):
        with st.expander(f"ğŸ”¹ {ch['name']}"):
            st.write(ch['content'])
            if st.button(f"ğŸ”Š {ch['name']} ë‚­ë…", key=f"btn_{idx}"):
                fname = f"chapter_{idx+1}.mp3"
                audio = google_premium_tts(ch['content'], fname, is_chapter=True)
                if audio:
                    st.audio(audio)
                    st.download_button(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ({fname})", audio, fname, "audio/mp3")

    st.divider()
    if st.button("ğŸš€ ë…¼ë¬¸ ì „ì²´ í†µí•© ìŒì› ìƒì„±", use_container_width=True):
        full_script = f"{f_title}. {data['summary']}. " + " ".join([ch['content'] for ch in data['chapters']])
        with st.spinner("ì „ì²´ ìŒì› í•©ì„± ì¤‘..."):
            audio = google_premium_tts(full_script, "original.mp3", is_chapter=True)
            if audio:
                st.audio(audio)
                st.download_button("ğŸ“¥ ì „ì²´ ë…¼ë¬¸ ë‹¤ìš´ë¡œë“œ (original.mp3)", audio, "original.mp3", "audio/mp3", use_container_width=True)
