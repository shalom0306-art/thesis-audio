import streamlit as st
from google.cloud import texttospeech
import fitz
import re
import os
import json

# --- 1. êµ¬ê¸€ ì¸ì¦ ì„¤ì • (í´ë¼ìš°ë“œ/ë¡œì»¬ ê²¸ìš© & í‚¤ ìë™ êµì • ê¸°ëŠ¥ ì¶”ê°€) ---
if "google_creds" in st.secrets:
    creds_dict = dict(st.secrets["google_creds"])
    # [í•µì‹¬ ìˆ˜ì •] private_keyì— ì„ì¸ ì¤„ë°”ê¿ˆ ê¸°í˜¸ì™€ ê³µë°±ì„ ê°•ì œë¡œ ì²­ì†Œí•©ë‹ˆë‹¤.
    if "private_key" in creds_dict:
        raw_key = creds_dict["private_key"]
        # ì‹¤ì œ ì¤„ë°”ê¿ˆ ë¬¸ìë¡œ ë³€í™˜í•˜ê³  ì•ë’¤ ê³µë°± ì œê±°
        cleaned_key = raw_key.replace("\\n", "\n").strip()
        creds_dict["private_key"] = cleaned_key

    with open("temp_key.json", "w") as f:
        json.dump(creds_dict, f)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "temp_key.json"
else:
    current_dir = os.path.dirname(os.path.abspath(__file__))
    KEY_PATH = os.path.join(current_dir, "google_key.json")
    if os.path.exists(KEY_PATH):
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = KEY_PATH

# --- 2. ìŒì› ì „ìš© í•„í„°ë§ ë° TTS ì—”ì§„ ---
def clean_for_audio(text, is_chapter=False):
    text = re.sub(r'\([a-zA-Z\s,./-]+\)', '', text)
    text = re.sub(r'\([^)]*\d{4}[^)]*\)', '', text)
    text = re.sub(r'\[\d+[\d\s,]*\]', '', text)
    text = text.replace("ì„œë¡ ", "ì„œë¡  <break time='1.5s'/>")
    if is_chapter:
        text = re.sub(r'^([^.!?\n]+)', r'\1 <break time="1.5s"/>', text)
    return text

def google_premium_tts(raw_text, filename, is_chapter=False):
    if not raw_text.strip(): return None
    try:
        client = texttospeech.TextToSpeechClient()
        audio_text = clean_for_audio(raw_text, is_chapter)
        max_chunk = 1000 
        text_chunks = [audio_text[i:i+max_chunk] for i in range(0, len(audio_text), max_chunk)]
        combined_audio = b""
        for chunk in text_chunks:
            ssml_text = f"<speak><prosody rate='1.1' pitch='0.0st'>{chunk}</prosody></speak>"
            response = client.synthesize_speech(
                input=texttospeech.SynthesisInput(ssml=ssml_text),
                voice=texttospeech.VoiceSelectionParams(
                    language_code="ko-KR", name="ko-KR-Neural2-B",
                    ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
                ),
                audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3, speaking_rate=1.1)
            )
            combined_audio += response.audio_content
        return combined_audio
    except Exception as e:
        st.error(f"âš ï¸ TTS ì˜¤ë¥˜: {str(e)}")
        return None

# --- 3. í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¡œì§ ---
def narrative_word_healer(text):
    text = re.sub(r'([ê°€-í£])\s?\n\s?([ê°€-í£])', r'\1\2', text)
    text = re.sub(r'([ì€ëŠ”ì´ê°€ì„ë¥¼ì˜ì—ë¡œì™€ê³¼,.\)\]!\?])\s?\n', r'\1 ', text)
    return re.sub(r'\s+', ' ', text).strip()

def extract_thesis(doc):
    full_text_raw = "".join([page.get_text("text") for page in doc])
    first_page_lines = doc[0].get_text("text").split('\n')
    title_parts = [l.strip() for l in first_page_lines if l.strip() and not any(k in l for k in ['ISSN', 'DOI'])][:2]
    title = re.sub(r'\s*\d+$', '', " ".join(title_parts)).strip()

    full_text = narrative_word_healer(full_text_raw)
    main_body = full_text.split("ì°¸ê³ ë¬¸í—Œ")[0].split("References")[0]
    abs_match = re.search(r'(êµ­\s*ë¬¸\s*ìš”\s*ì•½|ìš”\s*ì•½)(.*?)(Abstract|ì£¼\s*ì œ\s*ì–´|â… \.)', main_body, re.S)
    summary = narrative_word_healer(abs_match.group(2)) if abs_match else "ìš”ì•½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    chapters = []
    ch_splits = re.split(r'(ì œ\s*[1-5]\s*ì¥|â… \.|â…¡\.|â…¢\.|â…£\.|â…¤\.)', main_body)
    for i in range(1, len(ch_splits), 2):
        name, content = ch_splits[i].strip(), ch_splits[i+1].strip()
        if len(content) > 50: chapters.append({"name": name, "content": f"{name}. {content}"})
    return title, summary, chapters

# --- 4. ë©”ì¸ UI ---
st.set_page_config(page_title="ë…¼ë¬¸ ë‚˜ë ˆì´í„° Cloud", layout="wide")
st.title("ğŸ™ï¸ ë…¼ë¬¸ ë‚˜ë ˆì´í„° (Cloud ë²„ì „)")

uploaded_file = st.file_uploader("ë…¼ë¬¸ PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    if 'thesis_data' not in st.session_state:
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        t, s, c = extract_thesis(doc)
        st.session_state.thesis_data = {'title': t, 'summary': s, 'chapters': c}

    data = st.session_state.thesis_data
    f_title = st.text_input("ğŸ“„ ì œëª©", data['title'])
    
    if st.button("ğŸ”Š ì£¼ì œ + ìš”ì•½ ìŒì› ìƒì„±"):
        audio = google_premium_tts(f"{f_title}. {data['summary']}", "summary.mp3", is_chapter=True)
        if audio:
            st.audio(audio)
            st.download_button("ğŸ“¥ ë‹¤ìš´ë¡œë“œ (summary.mp3)", audio, "summary.mp3", "audio/mp3")

    st.divider()
    for idx, ch in enumerate(data['chapters']):
        with st.expander(f"ğŸ”¹ {ch['name']}"):
            st.write(ch['content'])
            if st.button(f"ğŸ”Š {ch['name']} ë‚­ë…", key=f"btn_{idx}"):
                audio = google_premium_tts(ch['content'], f"chapter_{idx+1}.mp3", is_chapter=True)
                if audio:
                    st.audio(audio)
                    st.download_button(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ (chapter_{idx+1}.mp3)", audio, f"chapter_{idx+1}.mp3", "audio/mp3")
