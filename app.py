import streamlit as st
from google.cloud import texttospeech
import fitz
import re
import os
import json

# --- 1. êµ¬ê¸€ ì¸ì¦ ì„¤ì • (í´ë¼ìš°ë“œ ë¹„ë°€ ê¸ˆê³  + ìœ ë ¹ ë¬¸ì ìë™ ì„¸ì²™) ---
if "google_creds" in st.secrets:
    creds_dict = dict(st.secrets["google_creds"])
    if "private_key" in creds_dict:
        pk = creds_dict["private_key"]
        header = "-----BEGIN PRIVATE KEY-----"
        footer = "-----END PRIVATE KEY-----"
        
        if header in pk and footer in pk:
            # [ì§„ë‹¨] 1625ì ì—ëŸ¬ ë° ìœ ë ¹ ë¬¸ì 'a'ë¥¼ ê°•ì œë¡œ ì§€ì›ë‹ˆë‹¤.
            body = pk.split(header)[1].split(footer)[0]
            clean_body = "".join(body.replace("\\n", "").split())
            valid_len = (len(clean_body) // 4) * 4
            clean_body = clean_body[:valid_len]
            creds_dict["private_key"] = f"{header}\n{clean_body}\n{footer}\n"

    with open("temp_key.json", "w") as f:
        json.dump(creds_dict, f)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "temp_key.json"
else:
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
    current_dir = os.path.dirname(os.path.abspath(__file__))
    KEY_PATH = os.path.join(current_dir, "google_key.json")
    if os.path.exists(KEY_PATH):
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = KEY_PATH

# --- 2. TTS ì—”ì§„ ---
def google_premium_tts(raw_text, filename, is_chapter=False):
    if not raw_text.strip(): return None
    try:
        client = texttospeech.TextToSpeechClient()
        # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
        clean_text = re.sub(r'\([ê°€-í£a-zA-Z\s,Â·]+\)', '', raw_text)
        
        max_chunk = 1000 
        text_chunks = [clean_text[i:i+max_chunk] for i in range(0, len(clean_text), max_chunk)]
        
        combined_audio = b""
        for chunk in text_chunks:
            ssml_text = f"<speak><prosody rate='1.1'>{chunk}</prosody></speak>"
            response = client.synthesize_speech(
                input=texttospeech.SynthesisInput(ssml=ssml_text),
                voice=texttospeech.VoiceSelectionParams(
                    language_code="ko-KR", name="ko-KR-Neural2-B"
                ),
                audio_config=texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
            )
            combined_audio += response.audio_content
        return combined_audio
    except Exception as e:
        st.error(f"âš ï¸ TTS ì˜¤ë¥˜: {str(e)}")
        return None

# --- 3. í…ìŠ¤íŠ¸ ì •ì œ ë° ì¶”ì¶œ ---
def narrative_word_healer(text):
    text = re.sub(r'([ê°€-í£])\s?\n\s?([ê°€-í£])', r'\1\2', text)
    text = re.sub(r'([ì€ëŠ”ì´ê°€ì„ë¥¼ì˜ì—ë¡œì™€ê³¼,.\)\]!\?])\s?\n', r'\1 ', text)
    return re.sub(r'\s+', ' ', text).strip()

def extract_thesis(doc):
    pages_content = [page.get_text("text") for page in doc]
    full_text = narrative_word_healer("\n".join(pages_content))
    
    # ì œëª© ì¶”ì¶œ
    first_page_lines = pages_content[0].split('\n')
    title = [l.strip() for l in first_page_lines if l.strip() and 'ISSN' not in l][:1][0]
    
    # ìš”ì•½ ë° ë³¸ë¬¸
    main_body = full_text.split("ì°¸ê³ ë¬¸í—Œ")[0].split("References")[0]
    abs_match = re.search(r'(ìš”\s*ì•½|êµ­ë¬¸ìš”ì•½)(.*?)(Abstract|â… \.)', main_body, re.S)
    summary = abs_match.group(2).strip() if abs_match else "ìš”ì•½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    chapters = []
    ch_splits = re.split(r'(â… \.|â…¡\.|â…¢\.|â…£\.|â…¤\.)', main_body)
    for i in range(1, len(ch_splits), 2):
        name, content = ch_splits[i], ch_splits[i+1].strip()
        if len(content) > 50:
            chapters.append({"name": name, "content": content})
    return title, summary, chapters

# --- 4. ë©”ì¸ UI ---
st.set_page_config(page_title="ë…¼ë¬¸ ë‚˜ë ˆì´í„°", layout="wide")
st.title("ğŸ™ï¸ ë…¼ë¬¸ ë‚˜ë ˆì´í„° (Smart & Clean)")

uploaded_file = st.file_uploader("ë…¼ë¬¸ PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    if 'thesis_data' not in st.session_state:
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        t, s, c = extract_thesis(doc)
        st.session_state.thesis_data = {'title': t, 'summary': s, 'chapters': c}

    data = st.session_state.thesis_data
    st.subheader("ğŸ“Œ 1. ì£¼ì œ ë° ìš”ì•½")
    f_title = st.text_input("ğŸ“„ ë…¼ë¬¸ ì œëª©", data['title'])
    
    if st.button("ğŸ”Š ì œëª© + ìš”ì•½ ìŒì› ìƒì„±"):
        audio = google_premium_tts(f"{f_title}. {data['summary']}", "summary.mp3")
        if audio:
            st.audio(audio)
            st.download_button("ğŸ“¥ MP3 ë‹¤ìš´ë¡œë“œ", audio, "summary.mp3")

    st.divider()
    st.subheader("ğŸ“– 2. ë³¸ë¬¸")
    for idx, ch in enumerate(data['chapters']):
        with st.expander(f"ğŸ”¹ {ch['name']}"):
            st.write(ch['content'][:1000] + "...")
            if st.button(f"ğŸ”Š {ch['name']} ë³€í™˜", key=f"btn_{idx}"):
                audio = google_premium_tts(ch['content'], f"chapter_{idx+1}.mp3")
                if audio: st.audio(audio)

    st.divider()
    st.subheader("ğŸš€ 3. ì „ì²´ í†µí•© ë³€í™˜")
    if st.button("ğŸ™ï¸ ë…¼ë¬¸ ì „ì²´ í†µí•© ìŒì› ìƒì„±", use_container_width=True):
        full_script = f"{f_title}. {data['summary']}. " + " ".join([ch['content'] for ch in data['chapters']])
        with st.spinner("ì „ì²´ ìŒì› í•©ì„± ì¤‘... (ìˆ˜ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
            audio = google_premium_tts(full_script, "full_thesis.mp3")
            if audio:
                st.success("âœ… ì „ì²´ ìŒì› ìƒì„± ì™„ë£Œ!")
                st.audio(audio)
